spark-shell --master yarn 
	--conf spark.ui.port=31644   (5 digit number)

sudo service hive-metastore status
sudo service hive-server2 status

spark-shell \
--master yarn \
--conf spark.ui.port=45645 \
--num-executors 1 \
--executor-memory 512M

#### to check whether spark is up and running use below 2 checks
sc
sqlContext

#### To start new Spark Context programmatically
sc.stop

import org.apache.spark.{SparkConf, SparkContext}
val conf = new SparkConf().setAppName("Test Conf and Context").setMaster("yarn-client")
val sc = new SparkContext(conf)

sc.getConf.getAll()

sc.getConf.getAll.foreach(println)

hadoop fs -put /root/database/retail_db/orders /database/


#### to check whether another spark context is running on same port or not 
ps aux | grep spark

OR

netstat -lnap | grep portNumber